{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Homework for Module 1\n",
    "\n",
    "Instead of doing SQL scripts, I thought it would be convenient to put it in one notebook, so I am using pandas to query the data."
   ],
   "id": "4c21de45b58ca782"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T17:29:00.797820Z",
     "start_time": "2025-01-26T17:29:00.793674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine,text"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question 1. Understanding docker first run\n",
    "> Run docker with the python:3.12.8 image in an interactive mode, use the entrypoint bash.\n",
    "> What's the version of pip in the image?\n",
    "\n",
    "- 24.3.1\n",
    "- 24.2.1\n",
    "- 23.3.1\n",
    "- 23.2.1"
   ],
   "id": "7f56991344874da9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:42:43.422292Z",
     "start_time": "2025-01-26T19:42:41.482437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# running it through the notebook to have proof for the homework\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['docker', 'run', '--rm', 'python:3.12.8', 'pip', '--version'],\n",
    "                        capture_output=True, text=True)\n",
    "\n",
    "# Print the result\n",
    "print(result.stdout)"
   ],
   "id": "ca88d839a36310aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.3.1 from /usr/local/lib/python3.12/site-packages/pip (python 3.12)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Question 2. Understanding Docker networking and docker-compose",
   "id": "25d892521ce11104"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# this is tricky to put here, but I was able to connect using both postgres:5432 and db:5432. I will go with db:5432.",
   "id": "7eb5a60add276d19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Connecting to database through SQLAlchemy",
   "id": "f9700176aeac84b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:29:48.451868Z",
     "start_time": "2025-01-26T17:29:48.447546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Best practices would be to put these values into environment variables or query secrets manager\n",
    "\n",
    "# user=os.environ['POSTGRES_USER']\n",
    "# password=os.environ['POSTGRES_PASSWORD']\n",
    "# host=os.environ['POSTGRES_HOST']\n",
    "\n",
    "# But since we are providing docker-compose.yml file with these values, it does not really matter\n",
    "user='postgres'\n",
    "password='postgres'\n",
    "host='localhost'\n",
    "port=5433\n",
    "database='ny_taxi'"
   ],
   "id": "e3d70f4dd2b72a6f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:30:14.695837Z",
     "start_time": "2025-01-26T17:30:14.656483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating engine - connect is not necessary, but it lets us verify the connection\n",
    "engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{database}')\n",
    "engine.connect()"
   ],
   "id": "c41280ec8f2f15b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x1d3a9672c90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:35:36.692890Z",
     "start_time": "2025-01-26T19:35:30.483785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lazy way is to query all the data with necessary joins. It works fast for me, but if we have larger dataset and structured report, we can optimize to only use columns needed for the report\n",
    "query = '''\n",
    "SELECT gtt.*,\n",
    "       puz.\"Borough\" as pu_borough,\n",
    "       puz.\"Zone\" as pu_zone,\n",
    "       doz.\"Borough\" AS do_borough,\n",
    "       doz.\"Zone\" AS do_zone\n",
    "FROM green_taxi_trips gtt\n",
    "         JOIN zones puz ON gtt.\"PULocationID\" = puz.\"LocationID\"\n",
    "         JOIN zones doz ON gtt.\"DOLocationID\" = doz.\"LocationID\"\n",
    "'''\n",
    "df =pd.read_sql(query,engine)"
   ],
   "id": "27d5fa8a4d0f98d9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question 3. Trip Segmentation Count\n",
    "> During the period of October 1st 2019 (inclusive) and November 1st 2019 (exclusive), how many trips, respectively, happened:\n",
    "\n",
    ">  - Up to 1 mile\n",
    ">  - In between 1 (exclusive) and 3 miles (inclusive),\n",
    ">  - In between 3 (exclusive) and 7 miles (inclusive),\n",
    ">  - In between 7 (exclusive) and 10 miles (inclusive),\n",
    ">  - Over 10 miles\n",
    "\n",
    "Pandas has a handy way to cut the dataset into specified bins, they do not have to be uniform. It is perfect for such categorizations and much more concise than CASE statements (although some may argue that not as easy to interpret)."
   ],
   "id": "9b26ffc405cd3eab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:35:41.555864Z",
     "start_time": "2025-01-26T19:35:41.533360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bins = [df['trip_distance'].min(),1,3,7,10,df['trip_distance'].max()]\n",
    "df['trip_distance_category'] = pd.cut(df['trip_distance'], bins=bins,include_lowest=True)"
   ],
   "id": "7b272c6ad1d09497",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:37:14.268447Z",
     "start_time": "2025-01-26T19:37:14.071034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\n",
    "    (df['lpep_pickup_datetime']>='2019-10-01') &\n",
    "    (df['lpep_dropoff_datetime']<'2019-11-01')\n",
    "].groupby('trip_distance_category',observed=True).size()"
   ],
   "id": "1a31ffe7201756d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trip_distance_category\n",
       "(-6.931, 1.0]     104802\n",
       "(1.0, 3.0]        198924\n",
       "(3.0, 7.0]        109603\n",
       "(7.0, 10.0]        27678\n",
       "(10.0, 515.89]     35189\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question 4. Longest trip for each day\n",
    "\n",
    "> Which was the pick up day with the longest trip distance? Use the pick up time for your calculations.\n",
    "\n",
    "> Tip: For every day, we only care about one single trip with the longest distance.\n",
    "\n",
    "- 2019-10-11\n",
    "- 2019-10-24\n",
    "- 2019-10-26\n",
    "- 2019-10-31"
   ],
   "id": "ac84d402db94e76f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:37:15.894983Z",
     "start_time": "2025-01-26T19:37:15.294761Z"
    }
   },
   "cell_type": "code",
   "source": "df['trip_pickup_day'] =(pd.to_datetime(df['lpep_pickup_datetime']).dt.strftime('%Y-%m-%d'))",
   "id": "9e67b033f9772a80",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:37:15.980217Z",
     "start_time": "2025-01-26T19:37:15.938507Z"
    }
   },
   "cell_type": "code",
   "source": "df.groupby('trip_pickup_day')['trip_distance'].max().sort_values(ascending=False).nlargest(5)",
   "id": "af1c03c8dfe0e252",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trip_pickup_day\n",
       "2019-10-31    515.89\n",
       "2019-10-11     95.78\n",
       "2019-10-26     91.56\n",
       "2019-10-24     90.75\n",
       "2019-10-05     85.23\n",
       "Name: trip_distance, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question 5. Three biggest pickup zones\n",
    "> Which were the top pickup locations with over 13,000 in total_amount (across all trips) for 2019-10-18?\n",
    "\n",
    "> Consider only lpep_pickup_datetime when filtering by date.\n",
    "\n",
    "- East Harlem North, East Harlem South, Morningside Heights\n",
    "- East Harlem North, Morningside Heights\n",
    "- Morningside Heights, Astoria Park, East Harlem South\n",
    "- Bedford, East Harlem North, Astoria Park"
   ],
   "id": "b778c9e80290d4ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:37:17.122195Z",
     "start_time": "2025-01-26T19:37:17.079346Z"
    }
   },
   "cell_type": "code",
   "source": "df[df['trip_pickup_day']=='2019-10-18'].groupby('pu_zone')['total_amount'].sum().sort_values(ascending=False)",
   "id": "17b8d2ae49bd9f5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pu_zone\n",
       "East Harlem North                   18686.68\n",
       "East Harlem South                   16797.26\n",
       "Morningside Heights                 13029.79\n",
       "Central Harlem                      12440.66\n",
       "Elmhurst                            12431.96\n",
       "                                      ...   \n",
       "Heartland Village/Todt Hill            24.80\n",
       "Inwood Hill Park                       24.03\n",
       "Forest Park/Highland Park              21.30\n",
       "Pelham Bay Park                        12.80\n",
       "Saint Michaels Cemetery/Woodside        7.60\n",
       "Name: total_amount, Length: 234, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question 6. Largest tip\n",
    "\n",
    "> For the passengers picked up in October 2019 in the zone named \"East Harlem North\" which was the drop off zone that had the largest tip?\n",
    "\n",
    "> Note: it's tip , not trip\n",
    "\n",
    "> We need the name of the zone, not the ID.\n",
    "\n",
    "- Yorkville West\n",
    "- JFK Airport\n",
    "- East Harlem North\n",
    "- East Harlem South"
   ],
   "id": "2831289114c76b38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:37:47.415806Z",
     "start_time": "2025-01-26T19:37:47.286569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\n",
    "    (df['lpep_pickup_datetime']>='2019-10-01') &\n",
    "    (df['lpep_pickup_datetime']<'2019-11-01') &\n",
    "    (df['pu_zone']=='East Harlem North')\n",
    "].groupby('do_zone')['tip_amount'].max().sort_values(ascending=False).nlargest(5)"
   ],
   "id": "fb778634b17c6d36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "do_zone\n",
       "JFK Airport              87.30\n",
       "Yorkville West           80.88\n",
       "East Harlem North        40.00\n",
       "Newark Airport           26.45\n",
       "Upper East Side North    18.45\n",
       "Name: tip_amount, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1f5e5460ae457116"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
